{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "VOCAB_SIZE=50304, BLOCK_SIZE=4, BATCH_SIZE=8, N_EMBED=768, DEVICE='cpu', BIAS=False, N_HEADS=12, N_LAYERS=12\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from constants import BLOCK_SIZE, BATCH_SIZE, VOCAB_SIZE, N_EMBED, DEVICE, BIAS, N_HEADS, N_LAYERS, DROP_OUT\n",
    "from model import BigramLanguageModel\n",
    "from train import get_batch\n",
    "from torch.nn import functional as F\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "decode = lambda x: enc.decode(x)\n",
    "print(f\"{VOCAB_SIZE=}, {BLOCK_SIZE=}, {BATCH_SIZE=}, {N_EMBED=}, {DEVICE=}, {BIAS=}, {N_HEADS=}, {N_LAYERS=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementing transformers \n",
    "data, targets = get_batch('eval')\n",
    "B, T = data.shape # batch, block size \n",
    "token2embd = nn.Embedding(VOCAB_SIZE, N_EMBED) # creates a matrix of size VOCAB_SIZE x N_EMBED\n",
    "pos2embd = nn.Embedding(BLOCK_SIZE, N_EMBED) # creates a matrix of size BLOCK_SIZE x N_EMBED,\n",
    "assert T <= BLOCK_SIZE, f\"Cannot forward sequence of length {T}, block size is only {BLOCK_SIZE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B=8, T=4, C=50304\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(VOCAB_SIZE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "logits = model(data)\n",
    "B, T, C = logits.shape\n",
    "logits = logits.view(B*T, C)\n",
    "print(f\"{B=}, {T=}, {C=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input=', to be asleep', ---> target=' to be asleep\\n',----> pred=', to be asleep sexy disadvantages explorer'\n",
      "input='-worn basis bow', ---> target=\"worn basis bow'd\",----> pred='-worn basis bow Scheme Special groove'\n",
      "input=' a health to all', ---> target=' health to all that',----> pred=' a health to all Kashmiraignammu'\n",
      "input=\" ha't.\\n\", ---> target=\"'t.\\n\\n\",----> pred=\" ha't.\\n dreamiar dull\"\n",
      "input='RIAN:\\n', ---> target='AN:\\nT',----> pred='RIAN:\\n relapse undefined plasma'\n",
      "input='\\nWhy, sir', ---> target='Why, sir,',----> pred='\\nWhy, siritiseless gimmick'\n",
      "input=\" solum:' to\", ---> target=\"um:' to the\",----> pred=\" solum:' to SHA EEG Admir\"\n",
      "input='IO:\\nI', ---> target=':\\nI confess',----> pred='IO:\\nIstsrespectiveivation'\n"
     ]
    }
   ],
   "source": [
    "out = model.predict_next(data ,3)\n",
    "for i in range(data.shape[0]): \n",
    "    input = decode(data[i].tolist())\n",
    "    target = decode(targets[i].tolist())\n",
    "    pred = decode(out[i].tolist())\n",
    "    print(f\"{input=}, \\t\\t {target=},\\t\\t {pred=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, batch=10, elapsed=267.62198519706726,cur_loss=12.121\n",
      "epoch=0, batch=20, elapsed=227.59489107131958,cur_loss=10.941\n",
      "epoch=0, batch=30, elapsed=225.29008102416992,cur_loss=11.103\n",
      "epoch=0, batch=40, elapsed=237.58062434196472,cur_loss=10.939\n",
      "epoch=0, batch=50, elapsed=245.77246618270874,cur_loss=10.937\n",
      "epoch=0, batch=60, elapsed=243.60992288589478,cur_loss=10.928\n",
      "epoch=0, batch=70, elapsed=252.03680109977722,cur_loss=10.771\n",
      "epoch=0, batch=80, elapsed=249.72417092323303,cur_loss=10.977\n",
      "epoch=0, batch=90, elapsed=245.49435710906982,cur_loss=10.834\n",
      "epoch=0, batch=100, elapsed=233.04064893722534,cur_loss=10.731\n",
      "epoch=0, batch=110, elapsed=234.2638258934021,cur_loss=10.707\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 768])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## implementing multi-head attension\n",
    "config = {\"n_heads\": N_HEADS, \n",
    "          \"n_embed\": N_EMBED,\n",
    "          \"n_layers\": N_LAYERS, \n",
    "          \"bias\": BIAS,\n",
    "          \"block_size\": BLOCK_SIZE,\n",
    "          'dropout': DROP_OUT, \n",
    "          'vocab_size': VOCAB_SIZE}\n",
    "config\n",
    "\n",
    "from model import MultiHeadAttention\n",
    "mha = MultiHeadAttention(config)\n",
    "tx = token2embd(data)\n",
    "mha(tx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.58M\n"
     ]
    }
   ],
   "source": [
    "## implementing GPT\n",
    "config = {\"n_heads\": N_HEADS, \n",
    "          \"n_embed\": N_EMBED,\n",
    "          \"block_size\": BLOCK_SIZE,\n",
    "          \"n_layers\": N_LAYERS, \n",
    "          \"bias\": BIAS, \n",
    "          'dropout': DROP_OUT, \n",
    "          'vocab_size': VOCAB_SIZE}\n",
    "config\n",
    "\n",
    "from model import GPT\n",
    "mogpt = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INA:\n",
      "I\n",
      " us,\n",
      "We\n",
      "\n",
      "He's within\n",
      "VINCENTIO\n",
      " therefore drawn between us\n",
      "IO:\n",
      "Here\n",
      " kennel home\n",
      " a lovely kiss!\n"
     ]
    }
   ],
   "source": [
    "for _ in data:\n",
    "    print(decode(_.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no,\n",
      "From protections polyg scholarship errors Blazers\n",
      " neither?\n",
      "\n",
      "driver derailed infectious').system\n",
      "? Justice or In Miner FIRST Sheridan close intensive\n",
      "ukedom?\n",
      "lictedcert WRITEdoi tattoos\n",
      ".\n",
      "Most welcomesein gradient Proceedings overwhelming Revision\n",
      " thy mother's tongue w Miss marketplace allowancevious\n",
      "ANIO:\n",
      " periodically Fred doctr apostird\n",
      " angry, does forget adults MAX Jeep caring crafts\n"
     ]
    }
   ],
   "source": [
    "y = mogpt.predict_next(data,5)\n",
    "for _ in y: \n",
    "    print(decode(_.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: permission denied (<Response [403]>)\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 403: Forbidden)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmogpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/moGPT/train.py:54\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, optimizer, num_epochs):\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mwandb_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     56\u001b[0m         model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/src/moGPT/train.py:20\u001b[0m, in \u001b[0;36mwandb_init\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwandb_init\u001b[39m(model):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m WANDB_LOG:\n\u001b[0;32m---> 20\u001b[0m         \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWANDB_PROJECT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWANDB_RUN_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreinit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATASET\u001b[39m\u001b[38;5;124m'\u001b[39m: DATASET,\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBATCH_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m: BATCH_SIZE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEVICE\u001b[39m\u001b[38;5;124m'\u001b[39m: DEVICE,\n\u001b[1;32m     28\u001b[0m         })\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m WANDB_KEY:\n",
      "File \u001b[0;32m~/miniconda3/envs/mogpt/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1178\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001b[39;00m\n\u001b[0;32m-> 1178\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/mogpt/lib/python3.12/site-packages/wandb/analytics/sentry.py:155\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception(exc)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# but hopefully it's not too bad\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/mogpt/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1164\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[1;32m   1163\u001b[0m     wi\u001b[38;5;241m.\u001b[39msetup(kwargs)\n\u001b[0;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mogpt/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:776\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m--> 776\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mCommError\u001b[0m: It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 403: Forbidden)"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "train(mogpt, optimizer,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no,\n",
      "From., https anythingceptions cloning\n",
      " neither?\n",
      "\n",
      "(),highest leftoverGW compiled\n",
      "? Justice or In knowledgeable've studies sweeping SC\n",
      "ukedom?\n",
      " Countdown Conflict altered Zan Residential\n",
      ".\n",
      "Most welcomearantine\\\", euphem dog Origin\n",
      " thy mother's tongueheddar Tunis Mutual recalna\n",
      "ANIO:\n",
      " fork Straw Peng Nath trauma\n",
      " angry, does forget unworthy forcefullyempl Euras affection\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = mogpt.predict_next(data, 5)\n",
    "for _ in y:\n",
    "    print(decode(_.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
